<div class="container">
    <h1>SIMD Instructions</h1>
    <hr>
    <h2>Motivation</h2>
    <p style="text-align: justify;">
        Suppose you are writing a game and at some point you have reached a phase where you want to optimize what you
        already have before moving on. Skimming through you code base and you have found the following code which
        applies gravity to all your entities in the scene. To simplify things we won't use inheritance which means
        we would have a monolitic class <code>Entity</code> in our game. For the purpose of this tutorial this is
        fine since <code>Entity</code> class in very small anyway.
    </p>
    <div class="alert alert-primary" role="alert">
        <strong>Note!</strong>
        <p style="text-align: justify;">
            Using this <code>Entity</code> as we are using in example below is very rarely found in games. What is most
            common to be found is a base class <code>GameObject</code> and having multiple classes (<code>Player</code>,
            <code>Monster</code>, etc) to derive from it. This have advantages but have negative impacts in
            performance. Here I'm being very generous and giving an headstart to our <code>Entity</code> class which
            will be further improved in terms of performance.
        </p>
    </div>
    <CodeViewer @code={{this.cpp_snippet_1}} />
    <p style="text-align: justify;">
        So you have decided that you want to measure how much time does it takes to aply gravity to every entity each
        frame. Furthermore you want to measure it with different entities count to have a rough estimate how does
        performance change with the entities growth.
    </p>
    <p style="text-align: justify;">
        So you created a profiler, done some measurements multiple times and averaged the results. Pulled out your
        favourite chart creation tool and came up with these results:
    </p>
    <div class="text-center">
        <img src="/images/tutorials/simd/measurement_01.png" width="65%">
    </div>
    <br>
    <div class="alert alert-primary" role="alert">
        <strong>Note!</strong>
        <p style="text-align: justify;">
            If you try to run this test on your machine you're likely to get different values. This is because there are
            many factors that impacts the performance (such as operating system, tasks running in background, CPU, etc).
        </p>
    </div>
    <p style="text-align: justify;">
        Note that execution times comes in <a id="microsecond-reminder" data-trigger="focus" role="button" href="#"
            onclick="return false;" data-toggle="popover" {{did-insert this.popovermicrosecondHelper}}>microseconds</a>.
        Now lets suppose you have other systems in your game that require more time so you must open reduce execution
        time other parts.
    </p>
    <p>
        Remember that if you want to achieve 30 stable FPS you frame must update under (approximately) 33ms.
        In our case it would take 4.4ms to update 65536 entities which is about 13.3% out of 33ms. Lets suppose we have
        measured the execution time of all of our systems and calculated the time it requires of a single 33ms frame.
    </p>
    <div class="text-center">
        <img src="/images/tutorials/simd/time_partition.png" width="50%">
    </div>
    <br>
    <p style="text-align: justify;">
        If we wanted to add more systems we only had 14.2% of 33ms (which is about 4.7ms). So you want to open more
        space there and decided to start from Gravity System because it is the easiest of them all and you know how to
        do it quickly. In real scenario you'll probably start from the most expensive system but for the sake of this
        tutorial we'll start with Gravity System.
    </p>
    <h2>SIMD Instructions</h2>
    <p style="text-align: justify;">
        SIMD instructions is what allow to do parallel calculations without use of threads. It stands for <b>S</b>ingle
        <b>I</b>nstruction <b>M</b>ultiple <b>D</b>ata also know as intrinsic functions or vectorized instructions. With
        one single instruction you can work on multiple data. Pretty cool, right? But before start using them we need to
        recap our basic knowledge about data types.
    </p>
    <p style="text-align: justify;">
        I'm pretty sure that somewhere somehow you have heard that different data tyes have different sizes. For
        example <code>char</code> is 1 byte (8 bits), <code>float</code> and <code>int</code> is 4 bytes
        (32 bits) and <code>long</code> and <code>double</code> is 8 bytes (64 bits) and yes it depends on CPU and
        operating system you have but nowadays it is the most common to find. So why does this matter? Well because with
        SIMD instructions you have a new primitive types which are 16 bytes wide (126 bits). With this size you can fit
        4 <code>floats</code> or 4 <code>ints</code> inside and manipulate them all at the same time (or instruction as
        I should say). There are actually even bigger data types available namely 32 bytes (256 bits) and even 64 bytes
        (512 bits) but you should check if you CPU <a id="cpu-simd-support" data-trigger="focus" role="button" href="#"
            onclick="return false;" data-toggle="popover" {{did-insert this.popoverCpuSupport}}>supports</a>
        these kind of data types before using them. CPUs actually has a special <a
            href="https://en.wikipedia.org/wiki/Processor_register">register</a> for them:
    </p>
    <ul>
        <li>XMM0-XMM15 which are 16 bytes wide (SSE data types)</li>
        <li>YMM0-YMM15 which are 32 bytes wide (AVX data types)</li>
        <li>ZMM0-YMM15 which are 64 bytes wide (AVX-512 data types)</li>
    </ul>
    <div class="alert alert-primary" role="alert">
        <strong>Note!</strong>
        <p style="text-align: justify;">
            Somes times you'll find people refering to SSE, AVX and AVX-512 as AVX, AVX2 and AVX-512 but I will stick
            with the former naming as it is what you can find on <a
                href="https://software.intel.com/sites/landingpage/IntrinsicsGuide/">Intel's Documentation</a>.
        </p>
    </div>
    <p style="text-align: justify;">
        Bellow you can see what are the SIMD data types (for <span class="badge badge-pill"
            style="background-color: darkgray;">SSE</span>, <span class="badge badge-pill"
            style="background-color: lightgreen;">AVX</span> and <span class="badge badge-pill"
            style="background-color: yellow;">AVX-512</span>), their sizes and what can they hold (<code>float</code>,
        <code>int</code> or <code>double</code>).
    </p>
    <div class="text-center">
        <img src="/images/tutorials/simd/data_types_sizes.png" width="100%">
    </div>
    <br>
    <p style="text-align: justify;">
        Now image what it is to manipulate 4, 8 or even 16 values at the same time. It is a huge performance increase. I
        hope that by this point you're already interested in explore more about SIMD.
    </p>
    <h2>How can we use it?</h2>
    <p style="text-align: justify;">
        First we need to include appropriate header files to take advantage of SIMD:
    </p>
    <CodeViewer @code={{this.cpp_snippet_2}} />
    <p style="text-align: justify;">
        Then lets create a simple program that adds 4 float with another 4 floats.
    </p>
    <CodeViewer @code={{this.cpp_snippet_3}} />
    <p style="text-align: justify;">
        To initialize a <code>__m128</code> variable we use <code>_mm_set_ps</code> which takes 4 floats and returns a
        <code>__m128</code>.
    </p>
    <div class="alert alert-danger" role="alert">
        <strong>Warning!</strong>
        <p style="text-align: justify;">
            Do not be fooled here. Although we are working with intrinsic operations the <code>_mm_set_ps</code> is
            actually setting <code>__m128</code> values sequentially. By this I mean it sets 32 bits of
            <code>__m128</code> one at the time (i.e. one instruction per each value set). How do I know it? Well Intel
            has a great <a id="intel-documentation" onclick="return false;" data-trigger="focus" role="button" href="#"
                data-toggle="popover" {{did-insert this.popoverIntelDocumentation}}>documentation</a> about it,
            you should definitely check out.
        </p>
    </div>
    <p style="text-align: justify;">
        We then use <code>_mm_add_ps</code> to add our floats together all in one instruction. I should mention that
        having things done in one instruction doesn't meen that it will be done in one CPU Clock Cycle. It would
        actually take about 3-4 cycles to complete the instruction. But don't worry most of CPU instructions take more
        than 1 cycle to complete and SIMD instructions are not different.
    </p>
    <p style="text-align: justify;">
        In the previous sample we are only using addition, we can can also perform subtraction, multiplication, division
        and mny other crazy operations. Nearly everything you can do with scalars you can do with SIMD instruction.
    </p>
    <p style="text-align: justify;">
        If you need you can also create <code>__m128</code> from a single <code>float</code> by calling
        <code>_mm_set_ps1</code> which takes one <code>float</code> as an argument and returns <code>__m128</code> with
        all 32 bits set to the <code>float</code> value. If you want you can even load data from a pointer.
    </p>
    <CodeViewer @code={{this.cpp_snippet_4}} />
    <p style="text-align: justify;">
        Note that our variable <code>values</code> in the previous example is of type <code>float const *</code>. This
        is no accident, the <code>_mm_load_ps</code> actually require <code>float const *</code> as an argument. Because
        of this people tend cast the <code>float *</code> directly to <code>__m128 *</code> and then dereference it when
        using functions.
    </p>
    <CodeViewer @code={{this.cpp_snippet_5}} />
    <p style="text-align: justify;">
        Another common way to set <code>__m128</code> variables is by using <a
            href="https://en.cppreference.com/w/cpp/language/union">unions</a> which allows you type to behave like one
        type or another type suiting your needs at that moment. This is perfect for this scenario because sometimes need
        might need <code>__m128</code> and other times we might need <code>float[4]</code>:
    </p>
    <CodeViewer @code={{this.cpp_snippet_6}} />
    <p style="text-align: justify;">
        Using unions has an advantage because we can set values very quickly and also retrieve them. Speaking of which,
        how do we get our results back? One way would be by using unions:
    </p>
    <CodeViewer @code={{this.cpp_snippet_7}} />
    <pre>Output:<code>9, 8, 7, 6</code></pre>
    <p style="text-align: justify;">
        Another way would be to cast values to <code>float *</code> and then access them individually. But you've
        probably guessed that there is a function for that aswell namely <code>_mm_store_ps</code>.
    </p>
    <CodeViewer @code={{this.cpp_snippet_8}} />
    <pre>Output:<code>8, 7, 6, 5</code></pre>
    <p style="text-align: justify;">
        Note how the output came in reversed order. This is because the <code>_mm_set_ps</code> sets values in reversed.
        If you want to maintain the order you would probably want to call <code>_mm_setr_ps</code>.
    </p>
    <p style="text-align: justify;">
        There is much more you can do with SIMD. You can do bitwise operations, comparisons, trigonometry, probabilistic
        operations and more. If you want something specific just check the <a
            href="https://software.intel.com/sites/landingpage/IntrinsicsGuide/">Intel's Documentation</a>.
    </p>
    <p style="text-align: justify;">
        Oh one more thing I forgot to mention. We'll only be working with SSE here but if you want to use AVX or even
        AVX-512 you just use appropriate naming for the functions (for example instead of <code>_mm_set_ps</code> you
        can use <code>_mm256_set_ps</code> or <code>_mm512_set_ps</code>) and variable types.
    </p>
    <h2>Back to Business</h2>
    <p style="text-align: justify;">
        Lets get back to our initial game where we apply gravity to each entity and see what can we do to improve it's
        performance.
    </p>
</div>

{{!--
<hr>
<div class="container-fluid">
    <div class="row">
        <div class="col-md-2">
            <h2>Content List</h2>
            <ul>
                <li><a href="#list-item-introduction">Introduction</a></li>
                <li><a href="#list-item-data-types-recap">Data types recap</a></li>
                <li><a href="#list-item-how-do-we-use-it">How do we use it?</a></li>
                <li><a href="#list-item-get-the-results-back">Get the results back</a></li>
                <li><a href="#list-item-the-setup">The Setup</a></li>
                <li><a href="#list-item-branchless-execution">Branchless Execution</a></li>
                <li><a href="#list-item-time-for-improvement-with-simd-instructions">Time for improvement with SIMD
                        instructions</a></li>
                <li><a href="#list-item-performance-measurements">Performance Measurements</a></li>
                <li><a href="#list-item-one-final-note">One final note</a></li>
            </ul>
        </div>
        <div class="col-md-10">
            <div class="container-fluid">
                <h1>SIMD (A.K.A intrinsic Instructions)</h1>
                <hr>
                <h2 id="list-item-introduction">Introduction</h2>
                <p>
                    This is a pratical introduction to SIMD in C++. Other languages such as C# also allow this kind of
                    operations but require their own API to do so. I will assume that you are comfortable to read simple
                    C++ code and have a basic understanding of pointers.
                </p>
                <p>
                    All code samples here were build and tested in <a
                        href="https://visualstudio.microsoft.com/vs/">Visual
                        Studio
                        2019</a> and
                    the source code can be found on <a
                        href="https://github.com/vadimsZinatulins/SIMD-Tutorial">github</a>.
                </p>
                <h2 id="list-item-data-types-recap">Data types recap</h2>
                <p>
                    I'm sure that somewhere somehow you have heard that different data tyes have different sizes. For
                    example <code>char</code> is 1 byte (8 bits), <code>float</code> and <code>ints</code> are 4 bytes
                    (32 bits) and <code>longs</code> and <code>doubles</code> are 8 bytes (64 bits) adn yes it also
                    depends on machine and operating system but nowadays it is the most common. So why does this matter?
                    Well because with intrinsic operations you have a new primitive types which are 16 bytes wide (126
                    bits) and 32 bytes wide (256 bits). CPUs actually has a special register for them:
                <ul>
                    <li>XMM0-XMM15 which are 16 bytes wide (SSE data types)</li>
                    <li>YMM0-YMM15 which are 32 bytes wide (AVX data types)</li>
                </ul>
                <h4>SSE data types</h4>
                <table class="table table-bordered">
                    <tbody>
                        <tr>
                            <td>__m128</td>
                            <td>float</td>
                            <td>float</td>
                            <td>float</td>
                            <td>float</td>
                            <td>4 x 32 bit float</td>
                        </tr>
                        <tr>
                            <td>__m128i</td>
                            <td>int</td>
                            <td>int</td>
                            <td>int</td>
                            <td>int</td>
                            <td>4 x 32 bit integer</td>
                        </tr>
                        <tr>
                            <td>__m128d</td>
                            <td colspan="2">double</td>
                            <td colspan="2">double</td>
                            <td>2 x 64 bit double</td>
                        </tr>
                    </tbody>
                </table>
                <h4>AVX data types</h4>
                <table class="table table-bordered">
                    <tbody>
                        <tr>
                            <td>__m256</td>
                            <td>float</td>
                            <td>float</td>
                            <td>float</td>
                            <td>float</td>
                            <td>float</td>
                            <td>float</td>
                            <td>float</td>
                            <td>float</td>
                            <td>8 x 32 bit float</td>
                        </tr>
                        <tr>
                            <td>__m256i</td>
                            <td>int</td>
                            <td>int</td>
                            <td>int</td>
                            <td>int</td>
                            <td>int</td>
                            <td>int</td>
                            <td>int</td>
                            <td>int</td>
                            <td>8 x 32 bit integer</td>
                        </tr>
                        <tr>
                            <td>__m256d</td>
                            <td colspan="2">double</td>
                            <td colspan="2">double</td>
                            <td colspan="2">double</td>
                            <td colspan="2">double</td>
                            <td>4 x 64 bit double</td>
                        </tr>
                    </tbody>
                </table>
                </p>
                <p>
                    We will only deal with SSE but if you want you can use AVX since most of the difference between them
                    is naming convetions by post fixing names with 256 or replacing entirely 128 by 256 (for example
                    instead of <code>__m128</code> you would use <code>__m256</code> or instead of
                    <code>_mm_set_ps</code> you would use <code>_mm256_set_ps</code>). It is up to you which one you
                    want to use.
                </p>
                <h2 id="list-item-how-do-we-use-it">How do we use it?</h2>
                <p>
                    Lets start with a simple program:
                </p>
                <CodeViewer @code={{this.snippet1}} />
                <p>
                    First things first we need to include the appropriate headers. We include <code>nmmintrin</code>
                    when we are working with SSE and include <code>immintrin</code> when we are working with AVX.
                </p>
                <p>
                    Inside <code>main</code> function we define two <code>__m128</code> operands and set their four
                    <code>floats</code> with <code>_mm_set_ps</code>. Although we are working
                    with SSE the <code>_mm_set_ps</code> is an sequential instruction, i.e. each of <code>__m128</code>
                    values will be set one after another in sequence. How do I know it? Well Intel has a great <a
                        id="intel-documentation" onclick="return false;" data-trigger="focus" role="button" href="#"
                        data-toggle="popover" {{did-insert this.popoverIntelDocumentation}}>documentation</a> about it,
                    you should definitely check out.
                </p>
                <p>
                    Then we add all values of <code>a</code> with all values of <code>b</code> in a single <a
                        id="instruction-info" onclick="return false;" data-trigger="focus" role="button" href="#"
                        data-toggle="popover" {{did-insert this.popoverInstructionInfo}}>instruction</a>
                    and store the result in
                    <code>res</code>.
                </p>
                <h2 id="list-item-get-the-results-back">Get the results back</h2>
                <p>
                    There are multiple ways to get the values from SSE variables. One way is to use SSE operations
                    themselves as such:
                </p>
                <CodeViewer @code={{this.snippet2}} />
                <pre>Output:<code>4, 3, 2, 1</code></pre>
                <p>
                    The <code>_mm_store_ps</code> will retrieve our values from an SSE variable but as you can see index
                    0 refers to last position in <code>_mm_set_ps</code>. Another way to get our values is by using
                    casts as follow:</p>
                <CodeViewer @code={{this.snippet3}} />
                <pre>Output:<code>4, 3, 2, 1</code></pre>
                <p>
                    Note that it will return the same output as the previous one. One last method that I want to show is
                    by using <a href="https://en.cppreference.com/w/cpp/language/union">unions</a>:
                </p>
                <CodeViewer @code={{this.snippet4}} />
                <p>
                    The last two techniques can also be used to set an SSE variable. With this knowledge in mind we can
                    start with optimizations using SIMD instructions.
                </p>
                <h2 id="list-item-the-setup">The Setup</h2>
                <p>
                    Lets suppose we are building a game and we are now writing the section responsable for dealing
                    damage to all entities caused by an explosion. Lets define our rules for the explosion.
                </p>
                <div class="text-center">
                    <img src="/images/tutorials/simd/explosion_rules.png" width="30%">
                </div>
                <p>
                    Our explosion will have two radius (R<sub>1</sub> and R<sub>2</sub>). The inner radius will deal the
                    total amount of damage caused by explosion. The outter radius will have calculated damage, i.e.
                    farther an entity is from the center of the explosion less damage it will take. Note that both
                    R<sub>1</sub> and R<sub>2</sub> have their origin at the center of the explosion.
                </p>
                <p>
                    After our first coding iterations we could end up with something like this.
                </p>
                <CodeViewer @code={{this.snippet5}} />
                <h2 id="list-item-branchless-execution">Branchless Execution</h2>
                <p>
                    The first step to improve performance is to remove all conditions we have inside our
                    <code>for loop</code>. To do that we could apply the partial damage
                    (<code>1 - (distance - explosion->r1 / (explosion->r2 - explosion->r1))</code>) to all entities but
                    this has two problems:
                <ol>
                    <li>
                        It would calculate this factor for all entities even if they are outside the explosion radius.
                        This is bad because if all entities are outside this still would be calculated for every single
                        entity compared to no calculations at all. It would also add extra operations for those who are
                        inside inner radius even though they would only require one subtraction.
                    </li>
                    <li>
                        If you do the maths you will find out that those entities that are inside inner radius would
                        take more damage that is defined in <code>Explosion</code> struct which could be a nice feature
                        but it is not what we want here. Also those entities that are outside explosion radius would
                        actually have an healing effect which could be a feature for another game.
                    </li>
                </ol>
                </p>
                <p>
                    For the first problem we have no solution. It is what it is. But we could still would have
                    performance increase even though we are doing more computation than what is needed. This is because
                    we removed the possibility of <a href="https://en.wikipedia.org/wiki/Branch_predictor">branch
                        perdiction</a> and our calculations are relatively simple which are very fast anyway.
                </p>
                <p>
                    For the second problem what we really need is to clamp our factor between 0 and 1. This would
                    prevent the explosion from dealing more damage than defined or from healing entities. To achieve
                    this we apply <code>std::min</code> and <code>std::max</code> to our damage
                    factor. Our function now looks like this:
                </p>
                <CodeViewer @code={{this.snippet6}} />
                <div class="alert alert-primary" role="alert">
                    <b>Note!</b>
                    <p>
                        Even though we are using <code>std::min</code> and <code>std::max</code> they internally use
                        <a href="https://www.w3schools.com/cpp/cpp_conditions_shorthand.asp">ternary operator</a> which
                        are conditionals. But there are CPU level instructions which can calculate min and max in one go
                        as we will se in the following section.
                    </p>
                </div>
                <h2 id="list-item-time-for-improvement-with-simd-instructions">Time for improvement with SIMD
                    instructions</h2>
                <p>
                    Now that our code inside <code>for loop</code> has no conditionals inside it we can start making
                    improvements using SIMD instructions. The SIMD version is as follows:
                </p>
                <CodeViewer @code={{this.snippet7}} />
                <p>
                    First we convert all explosion properties to <code>__m128</code> since they never change during the
                    execution. Then we perform all the operations needed to calculate new entities' health and lastly we
                    set these values to their corresponding entities. If to take a closer look at the last section
                    you'll notice that we set entities' health at reversed order. This is because we are also setting
                    the values in <code>_mm_set_ps</code> in reversed order.
                </p>
                <p>
                    And there you go. If you reached this farm you've learned most of SIMD operations needed to start
                    using them on your own. There could be a lot more a lot more that I could cover like bit masks, AVX
                    and ever bigger register operations but these are most of the same thing but with different naming
                    convetions (link post fixing with 256 instead of 128, etc.) adn bit masks are just bit manipulations
                    (they have their uses especially when it comes to conditionals).
                </p>
                <h2 id="list-item-extra-performance">Extra performance</h2>
                <p>
                    If you are familiar with the concept of Data Oriented Design then you can take full advantage of
                    SIMD operations. If you look at our entity array memory layout you will find something like this:
                </p>
                <div class="text-center">
                    <img src="/images/tutorials/simd/memory_layout.png" width="65%" />
                </div>
                <p>
                    And when we use <code>_mm_set_ps</code> the CPU must go to each entity and grab their attribute. For
                    example when we do
                    <code>_mm_set_ps(entities[i + 0].x, entities[i + 1].x, entities[i + 2].x, entities[i + 3].x)</code>
                    not only <code>_mm_set_ps</code> is sequential it goes through all entities one by one.
                </p>
                <div class="text-center">
                    <img src="/images/tutorials/simd/data_retrieval.png" width="65%" />
                </div>
                <p>
                    We can do better than this. If we rearrange our array to be something like an array of positions xs,
                    array of positions ys and array of healths separately we could use SSE operations to load our data.
                </p>
                <div class="text-center">
                    <img src="/images/tutorials/simd/efficient_memory_layout.png" width="25%" />
                </div>
                <p>
                    Now we can load 3 values in one go with <code>_mm_load_ps</code> which is much faster than
                    <code>_mm_set_ps</code>.
                </p>
                <div class="text-center">
                    <img src="/images/tutorials/simd/efficient_data_retrieval.png" width="60%" />
                </div>
                <p>Now we would end up with cold like this:</p>
                <CodeViewer @code={{this.snippet8}} />
                <p>
                    You can see that the code is a little bit smaller. And also I'm not actually using
                    <code>_mm_load_ps</code> but instead I just use a pointer cast to void some headaches with
                    <code>const</code>. If you take a look at the documentation you'll see that <code>_mm_load_ps</code>
                    actually takes an <code>float const*</code>. But this kind of memory layout is a huge boost in
                    performance.
                </p>
                <h2 id="list-item-performance-measurements">Performance Measurements</h2>
                <div class="text-center">
                    <img src="/images/tutorials/simd/chart.png" width="100%">
                </div>
                <p>
                    These are results of performance measurements on my machine. If you run similar tests on your
                    machine you might get something completely different. This is because of CPU not being the same,
                    application you have running on your background and many toher factors that might influence the
                    result. It is always important to measure.
                </p>
                <p>
                    You can deduce few things from the measurements. First is that packed update is alwats faster than
                    other updates (again this is on my machine). Another thing we can verify is that branchless update
                    is not always faster than normal update, it is only faster when the number of entities to update
                    reaches a certain threshold. Here it seems to be around 16K of entities. If you have an sharp eye
                    you can also see that the time it takes to compute with normal update increases exponentialy with
                    the number of entities while the packed update increases linearly.
                </p>
                <h2 id="list-item-one-final-note">One final note</h2>
                <p>
                    Whenever you are doing performance related work it is always important to measure the results so you
                    can have something to reason about. If you do this you might get surprised more times than you
                    expect.
                </p>
                <p>
                    Also when using SSE, AVX or even more advanced vectorized instruction (specially in C++) you
                    should always keep in mind the target hardware it is suppose to run. If not it might not even run at
                    all. With other languages such as C# you might get performance loss if you try use vectorized
                    instruction on hardware that does not suports it because it will emulate these instructions.
                </p>
            </div>
        </div>
    </div>
</div> --}}