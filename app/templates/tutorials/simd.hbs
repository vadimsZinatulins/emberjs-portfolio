<div class="container-fluid">
    <div class="row">
        <div class="col-md-2">
            <h2>Content List</h2>
            <ul>
                <li><a href="#list-item-introduction">Introduction</a></li>
                <li><a href="#list-item-data-types-recap">Data types recap</a></li>
                <li><a href="#list-item-how-do-we-use-it">How do we use it?</a></li>
                <li><a href="#list-item-get-the-results-back">Get the results back</a></li>
                <li><a href="#list-item-the-setup">The Setup</a></li>
                <li><a href="#list-item-branchless-execution">Branchless Execution</a></li>
                <li><a href="#list-item-time-for-improvement-with-simd-instructions">Time for improvement with SIMD
                        instructions</a></li>
                <li><a href="#list-item-performance-measurements">Performance Measurements</a></li>
                <li><a href="#list-item-one-final-note">One final note</a></li>
            </ul>
        </div>
        <div class="col-md-10">
            <div class="container-fluid">
                <h1>SIMD (A.K.A intrinsic Instructions)</h1>
                <hr>
                <h2 id="list-item-introduction">Introduction</h2>
                <p>
                    This is a pratical introduction to SIMD in C++. Other languages such as C# also allow this kind of
                    operations but require their own API to do so. I will assume that you are comfortable to read simple
                    C++ code and have a basic understanding of pointers.
                </p>
                <p>
                    All code samples here were build and tested in <a
                        href="https://visualstudio.microsoft.com/vs/">Visual
                        Studio
                        2019</a> and
                    the source code can be found on <a
                        href="https://github.com/vadimsZinatulins/SIMD-Tutorial">github</a>.
                </p>
                <h2 id="list-item-data-types-recap">Data types recap</h2>
                <p>
                    I'm sure that somewhere somehow you have heard that different data tyes have different sizes. For
                    example <code>char</code> is 1 byte (8 bits), <code>float</code> and <code>ints</code> are 4 bytes
                    (32 bits) and <code>longs</code> and <code>doubles</code> are 8 bytes (64 bits) adn yes it also
                    depends on machine and operating system but nowadays it is the most common. So why does this matter?
                    Well because with intrinsic operations you have a new primitive types which are 16 bytes wide (126
                    bits) and 32 bytes wide (256 bits). CPUs actually has a special register for them:
                <ul>
                    <li>XMM0-XMM15 which are 16 bytes wide (SSE data types)</li>
                    <li>YMM0-YMM15 which are 32 bytes wide (AVX data types)</li>
                </ul>
                <h4>SSE data types</h4>
                <table class="table table-bordered">
                    <tbody>
                        <tr>
                            <td>__m128</td>
                            <td>float</td>
                            <td>float</td>
                            <td>float</td>
                            <td>float</td>
                            <td>4 x 32 bit float</td>
                        </tr>
                        <tr>
                            <td>__m128i</td>
                            <td>int</td>
                            <td>int</td>
                            <td>int</td>
                            <td>int</td>
                            <td>4 x 32 bit integer</td>
                        </tr>
                        <tr>
                            <td>__m128d</td>
                            <td colspan="2">double</td>
                            <td colspan="2">double</td>
                            <td>2 x 64 bit double</td>
                        </tr>
                    </tbody>
                </table>
                <h4>AVX data types</h4>
                <table class="table table-bordered">
                    <tbody>
                        <tr>
                            <td>__m256</td>
                            <td>float</td>
                            <td>float</td>
                            <td>float</td>
                            <td>float</td>
                            <td>float</td>
                            <td>float</td>
                            <td>float</td>
                            <td>float</td>
                            <td>8 x 32 bit float</td>
                        </tr>
                        <tr>
                            <td>__m256i</td>
                            <td>int</td>
                            <td>int</td>
                            <td>int</td>
                            <td>int</td>
                            <td>int</td>
                            <td>int</td>
                            <td>int</td>
                            <td>int</td>
                            <td>8 x 32 bit integer</td>
                        </tr>
                        <tr>
                            <td>__m256d</td>
                            <td colspan="2">double</td>
                            <td colspan="2">double</td>
                            <td colspan="2">double</td>
                            <td colspan="2">double</td>
                            <td>4 x 64 bit double</td>
                        </tr>
                    </tbody>
                </table>
                </p>
                <p>
                    We will only deal with SSE but if you want you can use AVX since most of the difference between them
                    is naming convetions by post fixing names with 256 or replacing entirely 128 by 256 (for example
                    instead of <code>__m128</code> you would use <code>__m256</code> or instead of
                    <code>_mm_set_ps</code> you would use <code>_mm256_set_ps</code>). It is up to you which one you
                    want to use.
                </p>
                <h2 id="list-item-how-do-we-use-it">How do we use it?</h2>
                <p>
                    Lets start with a simple program:
                </p>
                <CodeViewer @code={{this.snippet1}} />
                <p>
                    First things first we need to include the appropriate headers. We include <code>nmmintrin</code>
                    when we are working with SSE and include <code>immintrin</code> when we are working with AVX.
                </p>
                <p>
                    Inside <code>main</code> function we define two <code>__m128</code> operands and set their four
                    <code>floats</code> with <code>_mm_set_ps</code>. Although we are working
                    with SSE the <code>_mm_set_ps</code> is an sequential instruction, i.e. each of <code>__m128</code>
                    values will be set one after another in sequence. How do I know it? Well Intel has a great <a
                        id="intel-documentation" onclick="return false;" data-trigger="focus" role="button" href="#"
                        data-toggle="popover">documentation</a> about it, you should definitely check out.
                </p>
                <p>
                    Then we add all values of <code>a</code> with all values of <code>b</code> in a single <a
                        id="instruction-info" onclick="return false;" data-trigger="focus" role="button" href="#"
                        data-toggle="popover">instruction</a>
                    and store the result in
                    <code>res</code>.
                </p>
                <h2 id="list-item-get-the-results-back">Get the results back</h2>
                <p>
                    There are multiple ways to get the values from SSE variables. One way is to use SSE operations
                    themselves as such:
                </p>
                <CodeViewer @code={{this.snippet2}} />
                <pre>Output:<code>4, 3, 2, 1</code></pre>
                <p>
                    The <code>_mm_store_ps</code> will retrieve our values from an SSE variable but as you can see index
                    0 refers to last position in <code>_mm_set_ps</code>. Another way to get our values is by using
                    casts as follow:</p>
                <CodeViewer @code={{this.snippet3}} />
                <pre>Output:<code>4, 3, 2, 1</code></pre>
                <p>
                    Note that it will return the same output as the previous one. One last method that I want to show is
                    by using <a href="https://en.cppreference.com/w/cpp/language/union">unions</a>:
                </p>
                <CodeViewer @code={{this.snippet4}} />
                <p>
                    The last two techniques can also be used to set an SSE variable. With this knowledge in mind we can
                    start with optimizations using SIMD instructions.
                </p>
                <h2 id="list-item-the-setup">The Setup</h2>
                <p>
                    Lets suppose we are building a game and we are now writing the section responsable for dealing
                    damage to all entities caused by an explosion. Lets define our rules for the explosion.
                </p>
                <div class="text-center">
                    <img src="/images/tutorials/simd/explosion_rules.png" width="550px">
                </div>
                <p>
                    Our explosion will have two radius (R<sub>1</sub> and R<sub>2</sub>). The inner radius will deal the
                    total amount of damage caused by explosion. The outter radius will have calculated damage, i.e.
                    farther an entity is from the center of the explosion less damage it will take. Note that both
                    R<sub>1</sub> and R<sub>2</sub> have their origin at the center of the explosion.
                </p>
                <p>
                    After our first coding iterations we could end up with something like this.
                </p>
                <CodeViewer @code={{this.snippet5}} />
                <h2 id="list-item-branchless-execution">Branchless Execution</h2>
                <p>
                    The first step to improve performance is to remove all conditions we have inside our
                    <code>for loop</code>. To do that we could apply the partial damage
                    (<code>1 - (distance - explosion->r1 / (explosion->r2 - explosion->r1))</code>) to all entities but
                    this has two problems:
                <ol>
                    <li>
                        It would calculate this factor for all entities even if they are outside the explosion radius.
                        This is bad because if all entities are outside this still would be calculated for every single
                        entity compared to no calculations at all. It would also add extra operations for those who are
                        inside inner radius even though they would only require one subtraction.
                    </li>
                    <li>
                        If you do the maths you will find out that those entities that are inside inner radius would
                        take more damage that is defined in <code>Explosion</code> struct which could be a nice feature
                        but it is not what we want here. Also those entities that are outside explosion radius would
                        actually have an healing effect which could be a feature for another game.
                    </li>
                </ol>
                </p>
                <p>
                    For the first problem we have no solution. It is what it is. But we could still would have
                    performance increase even though we are doing more computation than what is needed. This is because
                    we removed the possibility of <a href="https://en.wikipedia.org/wiki/Branch_predictor">branch
                        perdiction</a> and our calculations are relatively simple which are very fast anyway.
                </p>
                <p>
                    For the second problem what we really need is to clamp our factor between 0 and 1. This would
                    prevent the explosion from dealing more damage than defined or from healing entities. To achieve
                    this we apply <code>std::min</code> and <code>std::max</code> to our damage
                    factor. Our function now looks like this:
                </p>
                <CodeViewer @code={{this.snippet6}} />
                <div class="alert alert-primary" role="alert">
                    <b>Note!</b>
                    <p>
                        Even though we are using <code>std::min</code> and <code>std::max</code> they internally use
                        <a href="https://www.w3schools.com/cpp/cpp_conditions_shorthand.asp">ternary operator</a> which
                        are conditionals. But there are CPU level instructions which can calculate min and max in one go
                        as we will se in the following section.
                    </p>
                </div>
                <h2 id="list-item-time-for-improvement-with-simd-instructions">Time for improvement with SIMD
                    instructions</h2>
                <p>
                    Now that our code inside <code>for loop</code> has no conditionals inside it we can start making
                    improvements using SIMD instructions. The SIMD version is as follows:
                </p>
                <CodeViewer @code={{this.snippet7}} />
                <p>
                    First we convert all explosion properties to <code>__m128</code> since they never change during the
                    execution. Then we perform all the operations needed to calculate new entities' health and lastly we
                    set these values to their corresponding entities. If to take a closer look at the last section
                    you'll notice that we set entities' health at reversed order. This is because we are also setting
                    the values in <code>_mm_set_ps</code> in reversed order.
                </p>
                <p>
                    And there you go. If you reached this farm you've learned most of SIMD operations needed to start
                    using them on your own. There could be a lot more a lot more that I could cover like bit masks, AVX
                    and ever bigger register operations but these are most of the same thing but with different naming
                    convetions (link post fixing with 256 instead of 128, etc.) adn bit masks are just bit manipulations
                    (they have their uses especially when it comes to conditionals).
                </p>
                <h2 id="list-item-extra-performance">Extra performance</h2>
                <p>
                    If you are familiar with the concept of Data Oriented Design then you can take full advantage of
                    SIMD operations. If you look at our entity array memory layout you will find something like this:
                </p>
                <div class="text-center">
                    <img src="/images/tutorials/simd/memory_layout.png" />
                </div>
                <p>
                    And when we use <code>_mm_set_ps</code> the CPU must go to each entity and grab their attribute. For
                    example when we do
                    <code>_mm_set_ps(entities[i + 0].x, entities[i + 1].x, entities[i + 2].x, entities[i + 3].x)</code>
                    not only <code>_mm_set_ps</code> is sequential it goes through all entities one by one.
                </p>
                <div class="text-center">
                    <img src="/images/tutorials/simd/data_retrieval.png" />
                </div>
                <p>
                    We can do better than this. If we rearrange our array to be something like an array of positions xs,
                    array of positions ys and array of healths separately we could use SSE operations to load our data.
                </p>
                <div class="text-center">
                    <img src="/images/tutorials/simd/efficient_memory_layout.png" />
                </div>
                <p>
                    Now we can load 3 values in one go with <code>_mm_load_ps</code> which is much faster than
                    <code>_mm_set_ps</code>.
                </p>
                <div class="text-center">
                    <img src="/images/tutorials/simd/efficient_data_retrieval.png" />
                </div>
                <p>Now we would end up with cold like this:</p>
                <CodeViewer @code={{this.snippet8}} />
                <p>
                    You can see that the code is a little bit smaller. And also I'm not actually using
                    <code>_mm_load_ps</code> but instead I just use a pointer cast to void some headaches with
                    <code>const</code>. If you take a look at the documentation you'll see that <code>_mm_load_ps</code>
                    actually takes an <code>float const*</code>. But this kind of memory layout is a huge boost in
                    performance.
                </p>
                <h2 id="list-item-performance-measurements">Performance Measurements</h2>
                <div class="text-center">
                    <img src="/images/tutorials/simd/chart.png" width="1200px">
                </div>
                <p>
                    These are results of performance measurements on my machine. If you run similar tests on your
                    machine you might get something completely different. This is because of CPU not being the same,
                    application you have running on your background and many toher factors that might influence the
                    result. It is always important to measure.
                </p>
                <p>
                    You can deduce few things from the measurements. First is that packed update is alwats faster than
                    other updates (again this is on my machine). Another thing we can verify is that branchless update
                    is not always faster than normal update, it is only faster when the number of entities to update
                    reaches a certain threshold. Here it seems to be around 16K of entities. If you have an sharp eye
                    you can also see that the time it takes to compute with normal update increases exponentialy with
                    the number of entities while the packed update increases linearly.
                </p>
                <h2 id="list-item-one-final-note">One final note</h2>
                <p>
                    Whenever you are doing performance related work it is always important to measure the results so you
                    can have something to reason about. If you do this you might get surprised more times than you
                    expect.
                </p>
                <p>
                    Also when using SSE, AVX or even more advanced vectorized instruction (specially in C++) you
                    should always keep in mind the target hardware it is suppose to run. If not it might not even run at
                    all. With other languages such as C# you might get performance loss if you try use vectorized
                    instruction on hardware that does not suports it because it will emulate these instructions.
                </p>
            </div>
        </div>
    </div>
</div>